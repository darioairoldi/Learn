# How to Create a Prompt Orchestrating Multiple Agents

When building complex AI workflows, a single prompt file often isn't enough. Tasks like "create a new prompt following best practices" involve multiple distinct phasesâ€”research, building, validation, and fixingâ€”each requiring different expertise and tools. This article explains how to design an <mark>orchestrator prompt</mark> that coordinates specialized agents, including intelligent architecture analysis to determine when new agents need to be created.

## Table of Contents

- [ğŸ¯ The Problem: Complex Multi-Phase Workflows](#-the-problem-complex-multi-phase-workflows)
- [ğŸ—ï¸ Architecture Overview](#ï¸-architecture-overview)
- [ğŸ“‹ The Specialized Agent Pattern](#-the-specialized-agent-pattern)
- [ğŸ”€ Orchestrator Design: Phase-Based Coordination](#-orchestrator-design-phase-based-coordination)
- [ğŸ§  Intelligent Architecture Analysis (Phase 3)](#-intelligent-architecture-analysis-phase-3)
- [ğŸ”§ Handling Agent Creation Within the Workflow](#-handling-agent-creation-within-the-workflow)
- [ğŸ”„ The Complete Workflow](#-the-complete-workflow)
- [ğŸ’¡ Key Design Decisions](#-key-design-decisions)
- [ğŸ“ Implementation Example](#-implementation-example)
- [ğŸ¯ Conclusion](#-conclusion)
- [ğŸ“š References](#-references)

## ğŸ¯ The Problem: Complex Multi-Phase Workflows

Consider the task: **"Create a new prompt file following repository best practices."**

This seemingly simple request actually involves multiple distinct phases:

1. **Research**: Discover existing patterns, find similar prompts, identify conventions
2. **Architecture Analysis**: Determine if a single prompt suffices or if multiple agents are needed
3. **Building**: Generate the actual file(s) following discovered patterns
4. **Validation**: Check structure, conventions, and quality
5. **Fixing**: Address any issues found during validation

Each phase requires different:
- **Tools**: Research needs `semantic_search`, building needs `create_file`, validation needs `read_file`
- **Expertise**: Researcher mindset vs. builder mindset vs. quality auditor mindset
- **Access levels**: Some phases are read-only, others need write access

### The Monolithic Prompt Problem

A single prompt trying to do everything suffers from:

| Problem | Impact |
|---------|--------|
| **Tool Clash** | 20+ tools cause confusion and wrong tool selection |
| **Context Rot** | Instructions for later phases get "lost in the middle" |
| **Mixed Responsibilities** | Hard to maintain, debug, or improve individual phases |
| **No Reusability** | Can't reuse the "research" capability for other tasks |

### The Solution: Orchestrator + Specialized Agents

Split the monolithic prompt into:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          ORCHESTRATOR PROMPT                                â”‚
â”‚   prompt-design-and-create.prompt.md                        â”‚
â”‚                                                             â”‚
â”‚   â€¢ Gathers requirements (Phase 1)                          â”‚
â”‚   â€¢ Coordinates agent handoffs                              â”‚
â”‚   â€¢ Analyzes architecture needs (Phase 3)                   â”‚
â”‚   â€¢ Presents results at each phase                          â”‚
â”‚   â€¢ Does NOT implementâ€”delegates everything                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚             â”‚             â”‚             â”‚
        â–¼             â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RESEARCHERâ”‚ â”‚  BUILDER  â”‚ â”‚ VALIDATOR â”‚ â”‚  UPDATER  â”‚
â”‚           â”‚ â”‚           â”‚ â”‚           â”‚ â”‚           â”‚
â”‚ Phase 2   â”‚ â”‚ Phase 4   â”‚ â”‚ Phase 5   â”‚ â”‚ Phase 6   â”‚
â”‚ read-only â”‚ â”‚ write     â”‚ â”‚ read-only â”‚ â”‚ write     â”‚
â”‚ research  â”‚ â”‚ create    â”‚ â”‚ analyze   â”‚ â”‚ fix       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ—ï¸ Architecture Overview

### The Prompt Creation System

We designed a complete system for creating prompts and agents:

```
ORCHESTRATORS (Prompts)
â”œâ”€â”€ prompt-design-and-create.prompt.md    # Creates NEW prompts/agents
â””â”€â”€ prompt-review-and-validate.prompt.md  # Improves EXISTING prompts/agents

SPECIALIZED AGENTS (Prompt Domain)
â”œâ”€â”€ prompt-researcher.agent.md   # Research patterns, recommend templates
â”œâ”€â”€ prompt-builder.agent.md      # Create prompt files
â”œâ”€â”€ prompt-validator.agent.md    # Validate prompt quality
â””â”€â”€ prompt-updater.agent.md      # Fix validation issues

SPECIALIZED AGENTS (Agent Domain) - Created when needed
â”œâ”€â”€ agent-researcher.agent.md    # Research agent patterns
â”œâ”€â”€ agent-builder.agent.md       # Create agent files
â”œâ”€â”€ agent-validator.agent.md     # Validate agent quality
â””â”€â”€ agent-updater.agent.md       # Fix agent issues
```

### Why Separate Prompt vs. Agent Specialists?

While prompts and agents share similar structure, they have important differences:

| Aspect | Prompt Files | Agent Files |
|--------|--------------|-------------|
| **Location** | `.github/prompts/` | `.github/agents/` |
| **Extension** | `.prompt.md` | `.agent.md` |
| **Key Fields** | `agent: plan/agent`, `tools` | `tools`, `handoffs`, persona |
| **Focus** | Task workflow | Specialist role |
| **Templates** | `prompt-*.md` templates | Agent-specific templates |

A `prompt-builder` trained on prompt patterns may not produce optimal agent files. Hence the need for specialized `agent-builder` when creating agents.

## ğŸ“‹ The Specialized Agent Pattern

Each specialized agent follows a consistent structure:

### Agent Anatomy

```yaml
---
description: "One-sentence specialist description"
agent: plan  # or: agent (for write access)
tools:
  - tool_1    # Narrow scope: 3-7 tools max
  - tool_2
handoffs:
  - label: "Next Step"
    agent: next-agent
    send: true  # automatic or false for user approval
---

# Agent Name

[Role description - what this specialist does]

## Your Expertise
- [Capability 1]
- [Capability 2]

## ğŸš¨ CRITICAL BOUNDARIES

### âœ… Always Do
- [Required behaviors]

### âš ï¸ Ask First  
- [Actions requiring confirmation]

### ğŸš« Never Do
- [Prohibited actions]

## Process
[Phase-by-phase workflow]
```

### The Four Prompt Specialists

#### 1. prompt-researcher.agent.md
**Role**: Research specialist (read-only)

```yaml
agent: plan  # Read-only
tools:
  - semantic_search
  - read_file
  - file_search
  - grep_search
```

**Responsibilities**:
- Find similar existing prompts (3-5 examples)
- Analyze patterns and conventions
- Recommend appropriate template
- Provide implementation guidance

**Key Boundary**: Never creates or modifies files

#### 2. prompt-builder.agent.md
**Role**: File creation specialist

```yaml
agent: agent  # Write access
tools:
  - read_file
  - semantic_search
  - create_file
  - file_search
handoffs:
  - label: "Validate Prompt"
    agent: prompt-validator
    send: true  # Automatic validation
```

**Responsibilities**:
- Load and customize templates
- Apply research recommendations
- Create new prompt files
- Self-validate before handoff

**Key Boundary**: Creates NEW files only (never modifies existing)

#### 3. prompt-validator.agent.md
**Role**: Quality assurance specialist (read-only)

```yaml
agent: plan  # Read-only
tools:
  - read_file
  - grep_search
  - file_search
```

**Responsibilities**:
- Validate structure against template
- Check convention compliance
- Assess quality and completeness
- Produce detailed report with scores

**Key Boundary**: Never modifies filesâ€”only reports issues

#### 4. prompt-updater.agent.md
**Role**: Fix specialist

```yaml
agent: agent  # Write access
tools:
  - read_file
  - grep_search
  - replace_string_in_file
  - multi_replace_string_in_file
handoffs:
  - label: "Re-validate After Update"
    agent: prompt-validator
    send: true  # Automatic re-validation
```

**Responsibilities**:
- Apply fixes from validation report
- Make targeted, surgical changes
- Preserve existing structure
- Trigger re-validation

**Key Boundary**: Modifies EXISTING files only (never creates new)

## ğŸ”€ Orchestrator Design: Phase-Based Coordination

The orchestrator prompt coordinates the workflow through distinct phases:

### Orchestrator Structure

```yaml
---
name: prompt-create-orchestrator
description: "Orchestrates specialized agents to research, build, and validate"
agent: agent
tools:
  - read_file        # For Phase 1 requirements analysis
  - semantic_search  # For Phase 3 architecture analysis
handoffs:
  - label: "Research prompt requirements"
    agent: prompt-researcher
    send: false  # User reviews research
  - label: "Build prompt file"
    agent: prompt-builder
    send: false  # User reviews file
  - label: "Validate prompt quality"
    agent: prompt-validator
    send: true   # Automatic validation
---
```

### Phase Flow

```
Phase 1: Requirements Gathering (Orchestrator)
    â”‚
    â”‚ User provides: "Create a prompt for X"
    â”‚ Orchestrator extracts: type, scope, tools, constraints
    â”‚
    â–¼
Phase 2: Research (â†’ prompt-researcher)
    â”‚
    â”‚ Researcher returns: patterns, template recommendation, guidance
    â”‚ Orchestrator presents findings to user
    â”‚
    â–¼
Phase 3: Architecture Analysis (Orchestrator)
    â”‚
    â”‚ Orchestrator determines: single-prompt vs. orchestrator+agents
    â”‚ If complex: identifies which agents to create
    â”‚
    â–¼
Phase 4/4a/4b: Build (â†’ prompt-builder or agent-builder)
    â”‚
    â”‚ Builder creates file(s) following research
    â”‚ Orchestrator presents results to user
    â”‚
    â–¼
Phase 5: Validation (â†’ prompt-validator)
    â”‚
    â”‚ Validator checks quality, reports issues
    â”‚ Automatic handoff (send: true)
    â”‚
    â–¼
Phase 6: Fix (Optional â†’ prompt-updater)
    â”‚
    â”‚ If issues found: updater applies fixes
    â”‚ Re-validates automatically
    â”‚
    â–¼
âœ… Complete
```

### Handoff Configuration: `send: true` vs `send: false`

| Configuration | Behavior | Use When |
|---------------|----------|----------|
| `send: false` | User sees output, decides whether to proceed | User should review intermediate results |
| `send: true` | Automatic handoff, no user intervention | High confidence, routine validation |

**Our Pattern**:
- Research â†’ User reviews findings (`send: false`)
- Build â†’ User reviews file (`send: false`)
- Validate â†’ Automatic, builder self-checked (`send: true`)
- Fix â†’ Automatic re-validation (`send: true`)

## ğŸ§  Intelligent Architecture Analysis (Phase 3)

The orchestrator's most important job is **determining optimal architecture** for the task. This happens in Phase 3.

### The Architecture Decision Problem

When a user requests "Create a prompt for code review," should we create:

**Option A: Single Prompt**
- One file: `code-review.prompt.md`
- Contains all logic in one place
- Simpler but potentially bloated

**Option B: Orchestrator + Agents**
- Orchestrator: `code-review-orchestrator.prompt.md`
- Agents: `security-reviewer.agent.md`, `style-reviewer.agent.md`, etc.
- More complex but modular and reusable

### Phase 3: Architecture Analysis Process

```markdown
### Phase 3: Prompt and Agent Structure Definition (Orchestrator)

**Goal:** Analyze task requirements to determine optimal architecture.

#### 1. Task Complexity Assessment

Analyze requirements from Phase 1 and research from Phase 2:

**Multi-phase workflow?**
- Does task divide into distinct phases? (analyze â†’ execute â†’ validate)
- Are phases sequential with clear handoff points?

**Cross-domain expertise?**
- Does task span multiple domains? (code, tests, docs)
- Would different specialists have different tool needs?

**Complexity Level:**
- **Low**: Single focused task, one domain
- **Medium**: 2-3 steps, same tools
- **High**: 3+ phases, multiple domains, different tools per phase
```

### Decision Framework

| Criteria | Single Prompt | Orchestrator + Agents |
|----------|---------------|----------------------|
| **Phases** | 1-2 linear steps | 3+ distinct phases |
| **Domains** | Single domain | Cross-domain |
| **Tools** | Consistent tools | Different tools per phase |
| **Existing agents** | None applicable | 1+ agents reusable |
| **New agents** | None justified | Reusable specialists identified |
| **Complexity** | Low-Medium | Medium-High |

### Existing Agent Inventory

Before recommending new agents, the orchestrator checks what already exists:

```markdown
#### 2. Existing Agent Inventory

Search `.github/agents/` directory for applicable agents:

1. List all agents: `file_search` in `.github/agents/*.agent.md`
2. Read agent descriptions (YAML frontmatter + purpose sections)
3. Match agent capabilities to task phases
4. Evaluate: Can existing agents be reused or extended?

**Analysis output:**

### Existing Agents Applicable to Task

**Directly applicable:**
- `prompt-researcher` â†’ Research phase (100% match)
- `prompt-validator` â†’ Validation phase (100% match)

**Coverage:** 50% existing, 25% new, 25% orchestrator-only
```

### New Agent Opportunities

When existing agents don't cover all phases:

```markdown
#### 3. New Agent Opportunities

**Criteria for new agent:**
- [ ] Represents reusable specialist persona (not task-specific)
- [ ] Has distinct tool needs from other agents
- [ ] Could be coordinated by multiple orchestrators
- [ ] Has clear boundaries and single responsibility

**Anti-patterns (don't create agent):**
- Task-specific logic with no reuse potential
- Same tools as existing agent (extend instead)
- One-off implementation need

**Recommendation:**

### Recommended New Agents

**Agent 1: security-analyzer.agent.md**
- **Purpose:** Analyze code for security vulnerabilities
- **Reusability:** Security audits, PR reviews, compliance checks
- **Justification:** Distinct expertise, reusable across multiple workflows
```

## ğŸ”§ Handling Agent Creation Within the Workflow

When Phase 3 determines that new agents are needed, the workflow branches:

### Modified Build Phase

```
Phase 3 Output: "Orchestrator + Agents" recommended
    â”‚
    â”‚ New agents needed: 2
    â”‚ Existing agents reusable: 2
    â”‚
    â–¼
Phase 4a: Create New Agents (Iterative)
    â”‚
    â”‚ For each new agent:
    â”‚   â†’ Research agent patterns (prompt-researcher)
    â”‚   â†’ Build agent file (agent-builder)
    â”‚   â†’ Validate agent (agent-validator)
    â”‚   â†’ User reviews
    â”‚
    â–¼
Phase 4b: Create Orchestrator
    â”‚
    â”‚ Build orchestrator that coordinates:
    â”‚   - Existing agents
    â”‚   - Newly created agents
    â”‚
    â–¼
Phase 5: Validate All Files
```

### The Agent Creation Sub-Workflow

When creating agents, we need **agent-specific specialists**:

```yaml
# Phase 4a handoff for each new agent
handoff:
  label: "Build agent file: security-analyzer"
  agent: agent-builder  # NOT prompt-builder!
  send: false
  context: |
    Build new agent file from Phase 3 recommendations.
    
    Agent specifications:
    - Name: security-analyzer
    - Purpose: Analyze code for security vulnerabilities
    - Persona: Security expert
    - Tools: [read_file, grep_search, semantic_search]
    - Agent type: plan (read-only analysis)
    
    Create file at: .github/agents/security-analyzer.agent.md
```

### Why Separate `agent-builder` from `prompt-builder`?

| Aspect | prompt-builder | agent-builder |
|--------|----------------|---------------|
| **Output location** | `.github/prompts/` | `.github/agents/` |
| **Template knowledge** | Prompt templates | Agent templates |
| **Key patterns** | Phase workflows, tool lists | Personas, handoffs, expertise |
| **YAML focus** | `agent:`, `tools:`, `argument-hint:` | `tools:`, `handoffs:`, `description:` |

The builder needs domain-specific knowledge to produce optimal files.

### Iterative Agent Creation

When multiple agents are needed, create them iteratively:

```markdown
## Phase 4a Progress: Agent Creation

**Agents to create:** 2
**Agents completed:** 1

### Agent 1: security-analyzer.agent.md
**Status:** âœ… Created
**Path:** `.github/agents/security-analyzer.agent.md`
**Tools:** [read_file, grep_search, semantic_search]

### Agent 2: performance-analyzer.agent.md
**Status:** ğŸ”„ In Progress

**Proceed with Agent 2? (yes/no/review Agent 1)**
```

## ğŸ”„ The Complete Workflow

### Standard Flow (Single Prompt)

```
User: "Create a prompt to validate API documentation"

Phase 1: Requirements
â”œâ”€â”€ Type: validation (read-only)
â”œâ”€â”€ Scope: API docs files
â””â”€â”€ Tools: read_file, grep_search

Phase 2: Research â†’ prompt-researcher
â”œâ”€â”€ Found 3 similar prompts
â”œâ”€â”€ Template: prompt-simple-validation-template.md
â””â”€â”€ Key patterns identified

Phase 3: Architecture Analysis
â”œâ”€â”€ Complexity: Low
â”œâ”€â”€ Phases: 1 (validation only)
â””â”€â”€ Decision: Single Prompt âœ“

Phase 4: Build â†’ prompt-builder
â””â”€â”€ Created: api-docs-validation.prompt.md

Phase 5: Validate â†’ prompt-validator
â””â”€â”€ Status: PASSED âœ…

âœ… Complete: api-docs-validation.prompt.md ready for use
```

### Complex Flow (Orchestrator + New Agents)

```
User: "Create a comprehensive code review system"

Phase 1: Requirements
â”œâ”€â”€ Type: orchestration
â”œâ”€â”€ Scope: Full codebase review
â””â”€â”€ Multi-domain: security, style, performance, tests

Phase 2: Research â†’ prompt-researcher
â”œâ”€â”€ Found orchestration patterns
â”œâ”€â”€ Template: prompt-multi-agent-orchestration-template.md
â””â”€â”€ Identified 4 review domains

Phase 3: Architecture Analysis
â”œâ”€â”€ Complexity: High
â”œâ”€â”€ Phases: 4 distinct review phases
â”œâ”€â”€ Existing agents: 0 applicable
â”œâ”€â”€ New agents needed: 4
â””â”€â”€ Decision: Orchestrator + Agents âœ“

Phase 4a: Create Agents (Iterative)
â”œâ”€â”€ Agent 1: security-reviewer.agent.md âœ…
â”œâ”€â”€ Agent 2: style-reviewer.agent.md âœ…
â”œâ”€â”€ Agent 3: performance-reviewer.agent.md âœ…
â””â”€â”€ Agent 4: test-coverage-reviewer.agent.md âœ…

Phase 4b: Create Orchestrator â†’ prompt-builder
â””â”€â”€ Created: code-review-orchestrator.prompt.md
    â””â”€â”€ Coordinates all 4 new agents

Phase 5: Validate All â†’ prompt-validator
â”œâ”€â”€ security-reviewer.agent.md: PASSED âœ…
â”œâ”€â”€ style-reviewer.agent.md: PASSED âœ…
â”œâ”€â”€ performance-reviewer.agent.md: PASSED âœ…
â”œâ”€â”€ test-coverage-reviewer.agent.md: PASSED âœ…
â””â”€â”€ code-review-orchestrator.prompt.md: PASSED âœ…

âœ… Complete: Full code review system ready
```

## ğŸ’¡ Key Design Decisions

### 1. Orchestrator Never Implements

The orchestrator's only jobs are:
- Gather requirements
- Analyze architecture
- Hand off to specialists
- Present results

**Why?** Keeps orchestrator focused, prevents context bloat, ensures specialists have full context for their domain.

### 2. Builder Creates, Updater Modifies

Clear separation of responsibilities:

| Action | Agent |
|--------|-------|
| Create NEW file | `prompt-builder` or `agent-builder` |
| Modify EXISTING file | `prompt-updater` or `agent-updater` |

**Why?** Prevents accidental overwrites, different tools needed (create_file vs. replace_string_in_file).

### 3. Automatic Validation After Build

```yaml
handoffs:
  - label: "Validate"
    agent: prompt-validator
    send: true  # Automatic
```

**Why?** Builder already self-checks, validation is routine, reduces user fatigue.

### 4. Automatic Re-validation After Fix

```yaml
# In prompt-updater
handoffs:
  - label: "Re-validate After Update"
    agent: prompt-validator
    send: true  # Automatic
```

**Why?** Ensures fixes actually resolved issues, creates feedback loop.

### 5. User Approval for Research and Build

```yaml
handoffs:
  - label: "Research"
    agent: prompt-researcher
    send: false  # User reviews
  - label: "Build"
    agent: prompt-builder
    send: false  # User reviews
```

**Why?** User should validate research direction and review generated files before validation.

## ğŸ“ Implementation Example

### The Orchestrator YAML

```yaml
---
name: prompt-create-orchestrator
description: "Orchestrates specialized agents to research, build, and validate new prompt/agent files"
agent: agent
model: claude-sonnet-4.5
tools:
  - read_file
  - semantic_search
handoffs:
  - label: "Research prompt requirements and patterns"
    agent: prompt-researcher
    send: false
  - label: "Build prompt file from research"
    agent: prompt-builder
    send: false
  - label: "Build agent file from research"
    agent: agent-builder
    send: false
  - label: "Validate prompt quality"
    agent: prompt-validator
    send: true
  - label: "Validate agent quality"
    agent: agent-validator
    send: true
argument-hint: 'Describe the prompt you want to create: purpose, type, target task'
---
```

### Phase 3 Architecture Decision Output

```markdown
## Phase 3 Complete: Architecture Analysis

### Task Complexity
**Level:** High
**Phases identified:** 4
- Phase 1: Security analysis
- Phase 2: Style review
- Phase 3: Performance analysis
- Phase 4: Test coverage check

**Domains:** [security, style, performance, testing]
**Tool variation:** Yes (different tools per phase)

### Agent Inventory
**Existing agents applicable:** 0
**New agents recommended:** 4
- `security-reviewer` â†’ Phase 1 (reusable for: security audits)
- `style-reviewer` â†’ Phase 2 (reusable for: PR reviews)
- `performance-reviewer` â†’ Phase 3 (reusable for: optimization)
- `test-reviewer` â†’ Phase 4 (reusable for: coverage checks)

### Architecture Recommendation

**Recommended approach:** Orchestrator + Agents

**Justification:**
Task has 4 distinct phases spanning multiple domains. Each phase benefits from specialized expertise and different tool sets. All 4 proposed agents are highly reusable for other workflows.

**Implementation strategy:**
1. Create 4 new agents first (Phase 4a)
2. Create orchestrator to coordinate them (Phase 4b)
3. Validate all files (Phase 5)

**Proceed to build phase? (yes/no/modify)**
```

## ğŸ¯ Conclusion

Building complex AI workflows requires moving beyond monolithic prompts to orchestrated multi-agent systems. The key principles are:

### Design Principles

1. **Separation of Concerns**: Each agent does one thing well
2. **Narrow Tool Scope**: 3-7 tools per agent maximum
3. **Clear Handoffs**: Explicit transitions between agents
4. **Architecture Intelligence**: Orchestrator analyzes complexity before building
5. **Iterative Creation**: Build agents one at a time with validation
6. **Automatic Validation**: Reduce friction for routine quality checks

### The Pattern

```
Orchestrator (coordinates, never implements)
    â”‚
    â”œâ”€â”€ Researcher (read-only, discovers patterns)
    â”œâ”€â”€ Builder (write, creates new files)
    â”œâ”€â”€ Validator (read-only, checks quality)
    â””â”€â”€ Updater (write, fixes issues)
```

### When to Use This Pattern

| Scenario | Approach |
|----------|----------|
| Simple, focused task | Single prompt file |
| Multi-phase workflow | Orchestrator + existing agents |
| Complex, multi-domain task | Orchestrator + new specialized agents |
| Improving existing prompts | Different orchestrator (review-and-validate) |

By following this pattern, you create maintainable, reusable, and reliable AI workflows that scale with complexity.

## ğŸ“š References

- [GitHub Blog: How to Write Great Agents.md](https://github.blog/ai-and-ml/github-copilot/how-to-write-a-great-agents-md-lessons-from-over-2500-repositories/) - Analysis of 2,500+ agent files
- [VS Code: Custom Agents Documentation](https://code.visualstudio.com/docs/copilot/copilot-customization) - Official agent documentation
- [Microsoft: Prompt Engineering Techniques](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/prompt-engineering) - Context engineering principles
- [04. How to Structure Content for Copilot Agent Files](./04.%20how_to_structure_content_for_copilot_agent_files.md) - Agent file structure guide
- [03. How to Structure Content for Copilot Prompt Files](./03.%20how_to_structure_content_for_copilot_prompt_files.md) - Prompt file structure guide

---

<!-- 
---
article_metadata:
  filename: "05. how_to_create_a_prompt_interacting_with_agents.md"
  created: "2025-12-10T00:00:00Z"
  last_updated: "2025-12-10T00:00:00Z"
  author: "prompt-builder"
  
validations:
  structure:
    status: null
    last_run: null
  grammar:
    status: null
    last_run: null
---
-->
