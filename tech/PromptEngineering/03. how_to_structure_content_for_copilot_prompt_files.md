# How to Structure Content for GitHub Copilot Prompt Files

Designing effective prompt files is key to obtaining accurate and useful responses from GitHub Copilot. Prompt files (`*.prompt.md`) let you define <mark>reusable prompts that generate code or documentation in a structured way</mark>. Here we discuss best practices for structuring your prompt files and note the differences in functionality between **Visual Studio Code** and **Visual Studio**.

## Table of Contents

- [üìã YAML Frontmatter](#-yaml-frontmatter)
- [‚úçÔ∏è Compose Clear and Structured Content](#Ô∏è-compose-clear-and-structured-content)
- [üìÅ Organize Supporting Materials](#-organize-supporting-materials)
- [‚öôÔ∏è Environment-Specific Considerations](#Ô∏è-environment-specific-considerations)
- [üéØ Conclusion](#-conclusion)
- [üìö References](#-references)

# üìã YAML Frontmatter

Prompt files may start with a <mark>**YAML frontmatter**</mark> enclosed by `---`. This header configures how the prompt appears in the Chat UI and how it executes:

- <mark>**name**</mark>: Identifier for the slash/hashtag command. If omitted, Copilot uses the filename. 
- <mark>**description**</mark>: Shown when selecting the prompt in the picker. Provides context to your team.
- <mark>**agent**</mark>: Sets the chat mode (`ask`, `edit`, `agent` or a custom agent name). 
- <mark>**model**</mark>: Chooses a specific LLM; otherwise Copilot uses the default. 
- <mark>**tools**</mark>: Restricts which tools (e.g., `fetch`, `codebase`, specific MCP servers) the prompt can access. 
- **argument-hint**: Suggests how to provide arguments when running the prompt (visible in the input field).

These metadata fields are supported in **VS Code** and in **Visual Studio 17.10+**; however, not all features (such as custom agent names or specific tools) may be fully supported by Visual Studio yet. Check the release notes for your version to see which fields are functional.

Here‚Äôs a sample YAML header:

```yaml
---
name: react-form
agent: ask
model: GPT-4
description: "Generate a React form component from a list of fields."
tools: ['codebase', 'fetch']
argument-hint: 'fields=field1:string,field2:number...'
---
```

# ‚úçÔ∏è Compose Clear and Structured Content

The body of a prompt file contains the actual instructions. <mark>Use concise, direct language to convey the task</mark>. Organize content with headings and bullet points to make it easy for both humans and the LLM to follow.

### Define the Role and Objective
<mark>Start by stating the persona and mission</mark>. For example: "You are a senior software engineer preparing a code scaffold for a new feature. Generate a file structure, include doc comments, mark TODOs where logic should be implemented, and create supporting files (e.g., package.json)."

### Use Bullet Points
<mark>Enumerate requirements or tasks clearly. **LLMs process bullet lists effectively**</mark>, which results in more organized responses.  

For example:
- Include comments explaining each function.
- Add a `TODO` placeholder in functions that need implementation.
- Create `.env` placeholders for environment variables.
- Generate dependency files if needed.

### Provide an Input Template
For prompts that require user input, include a <mark>**user-editable template**</mark> with placeholders. <mark>Wrap variable sections in double braces</mark> to signal that they should be replaced. Organize these placeholders under subheadings, such as:

```
## Use Case
{{Describe the business problem and high-level goal.}}

## Target Functionality
{{List the key methods or endpoints to implement.}}

## Technologies
{{Specify languages, frameworks and versions.}}
```

### Include Examples (Optional)
Providing example input and output demonstrates the expected result. For instance, when instructing Copilot to create a README, show a sample section to illustrate tone and structure.

### Reference Tools, Files and Variables
In VS Code, you can leverage <mark>chat variables and tools directly within prompts</mark>:

- Use `${workspaceFolder}`, `${file}` or `${selection}` to embed context about the current workspace, file or selection.
- Use `#fetch <url>` to pull content from a URL, or `#codebase` to search your repository. These features are fully supported in VS Code Chat and may be partially available in Visual Studio Chat (depending on version). 

Visual Studio currently supports fewer chat variables/tools; check the official docs for the latest list of supported chat commands.

# üìÅ Organize Supporting Materials

Complex prompts often require reusable snippets or deeper context.  
Organize these resources strategically:

- <mark>**Prompt snippets**</mark>: Create a folder such as `.github/prompt-snippets/` for reusable sections (e.g., code review guidelines, test boilerplates) that you reference from multiple prompts via Markdown links. 
- <mark>**Project documentation**</mark>: Use a `.copilot/context/` (optional) folder to store rich information‚ÄîAPI contracts, data schemas, domain terms, architecture decisions and diagrams‚Äîwhich <mark>the Copilot engine can search</mark>. VS Code and Visual Studio both index these files to improve the relevance of suggestions.
- **Example outputs**: Including example outputs (e.g., a table of tests to generate) can guide the model's formatting and structure. When adding examples, clearly mark them so readers know they're illustrative.

# ‚öôÔ∏è Environment-Specific Considerations

| Feature or Recommendation | VS Code (1.106+ Preview) | Visual Studio 17.10+ |
|---|---|---|
| **.prompt.md support** | Yes. Slash commands `/promptName` run workspace or user prompts. | Yes, since version 17.10. Hashtag commands `#promptName` run workspace prompts. |
| **User prompt files** | Supported. Stored in `~/.config/Code/User/prompts` (Linux) or `%APPDATA%\Code\User\prompts` (Windows). Appear across all workspaces as slash commands. | Not supported. Only workspace prompts are recognized. |
| **Tools and variables** | Extensive support for `#fetch`, `#codebase`, `${file}`, `${selection}`, etc. | Limited support; see Visual Studio docs for current tools and variables. |
| **Custom agents** | `.agent.md` files in `.github/agents` define specialized personas. Available in VS Code 1.106+ (Preview). | Custom agents are not defined via `.agent.md` files. Visual Studio uses a separate `AGENTS.md` concept for guiding its coding agents. |

# üéØ Conclusion

<mark>Effective prompt-file design combines a well-crafted YAML header with a clear, structured body and often includes templates or examples</mark>. By respecting the official file locations (e.g., `.github/prompts/` for prompt files) and understanding the differences between VS Code and Visual Studio capabilities, you can create prompt libraries that provide consistent and high-quality results across your development environments.

# üìö References

## Official GitHub Copilot Documentation

- **[GitHub Copilot Prompt Engineering Guide](https://docs.github.com/en/copilot/using-github-copilot/prompt-engineering-for-github-copilot)**  
  *This comprehensive guide from GitHub provides foundational strategies for crafting effective prompts when working with GitHub Copilot. It covers general prompt engineering principles that apply across different Copilot interfaces and is essential reading for understanding how to communicate effectively with the AI assistant.*

- **[Creating Custom Prompts for GitHub Copilot](https://code.visualstudio.com/docs/copilot/copilot-custom-prompts)**  
  *The official VS Code documentation explains how to create and use `.prompt.md` files in your workspace. This reference is directly relevant as it details the YAML frontmatter options, file locations, and slash command syntax covered in this article.*

- **[GitHub Copilot in Visual Studio](https://learn.microsoft.com/en-us/visualstudio/ide/visual-studio-github-copilot-extension)**  
  *Microsoft's documentation for GitHub Copilot in Visual Studio provides specific information about prompt file support (available from version 17.10+) and explains the differences in functionality between Visual Studio and VS Code, which is crucial for understanding the environment-specific considerations discussed in this article.*

## Prompt Engineering Best Practices

- **[OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)**  
  *While this guide is focused on OpenAI's models, the prompt engineering principles it discusses (clarity, specificity, providing examples, and iterative refinement) are universally applicable to GitHub Copilot. This reference helps readers understand the underlying LLM behavior that makes structured prompts effective.*

- **[Anthropic's Prompt Engineering Tutorial](https://docs.anthropic.com/en/docs/prompt-engineering)**  
  *This tutorial offers insights into how large language models interpret instructions, including the importance of clear role definition, structured formatting, and providing context‚Äîall concepts that directly support the best practices outlined in this article for creating effective prompt files.*

## Community Resources and Examples

- **[Awesome GitHub Copilot](https://github.com/jmathai/awesome-copilot)**  
  *A curated list of resources, examples, and community-contributed prompt patterns for GitHub Copilot. This repository is valuable for seeing real-world examples of prompt files and learning from how other developers structure their reusable prompts.*

- **[VS Code Copilot Extension Changelog](https://github.com/microsoft/vscode-docs/blob/main/docs/copilot/copilot-vscode-features.md)**  
  *Tracking the VS Code Copilot extension's feature updates helps readers stay current with new capabilities (like custom agents and tool restrictions) that affect how prompt files can be structured and what functionality they can leverage.*

